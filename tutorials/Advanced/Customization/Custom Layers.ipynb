{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c446e37aee10>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# In the tf.keras.layers package, layers are objects. To construct a layer,\n",
    "# simply construct the object. Most layers take as a first argument the number\n",
    "# of output dimensions / channels.\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "# The number of input dimensions is often unnecessary, as it can be inferred\n",
    "# the first time the layer is used, but it can be provided if you want to\n",
    "# specify it manually, which is useful in some complex models.\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use a layer, simply call it.\n",
    "layer(tf.zeros([10, 5]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n array([[-0.07820755, -0.35472423, -0.33291033, -0.12229198,  0.13671947,\n          0.04017973,  0.30425435, -0.17597681,  0.3455888 ,  0.28213495],\n        [-0.4871316 , -0.4500637 ,  0.5276838 ,  0.4304729 , -0.60655206,\n         -0.02040946, -0.39246994,  0.58272356,  0.01984656, -0.31247538],\n        [-0.07082051, -0.5907985 ,  0.20747393, -0.45610112, -0.17349648,\n         -0.55453146, -0.47197318,  0.556495  ,  0.06004244,  0.17278308],\n        [-0.32963955, -0.28614366,  0.57288104, -0.5853654 ,  0.1968996 ,\n         -0.21841267,  0.32983965, -0.5548594 , -0.6170287 ,  0.43566614],\n        [ 0.02472442, -0.0730257 , -0.24351996, -0.456232  ,  0.14912397,\n          0.29163253,  0.26199102,  0.14669615,  0.24232161, -0.6131984 ]],\n       dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layers have many useful methods. For example, you can inspect all variables\n",
    "# in a layer using `layer.variables` and trainable variables using\n",
    "# `layer.trainable_variables`. In this case a fully-connected layer\n",
    "# will have variables for weights and biases.\n",
    "layer.variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n array([[-0.07820755, -0.35472423, -0.33291033, -0.12229198,  0.13671947,\n          0.04017973,  0.30425435, -0.17597681,  0.3455888 ,  0.28213495],\n        [-0.4871316 , -0.4500637 ,  0.5276838 ,  0.4304729 , -0.60655206,\n         -0.02040946, -0.39246994,  0.58272356,  0.01984656, -0.31247538],\n        [-0.07082051, -0.5907985 ,  0.20747393, -0.45610112, -0.17349648,\n         -0.55453146, -0.47197318,  0.556495  ,  0.06004244,  0.17278308],\n        [-0.32963955, -0.28614366,  0.57288104, -0.5853654 ,  0.1968996 ,\n         -0.21841267,  0.32983965, -0.5548594 , -0.6170287 ,  0.43566614],\n        [ 0.02472442, -0.0730257 , -0.24351996, -0.456232  ,  0.14912397,\n          0.29163253,  0.26199102,  0.14669615,  0.24232161, -0.6131984 ]],\n       dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variables are also accessible through nice accessors\n",
    "layer.kernel, layer.bias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # build存在的好处在文档里说明过，可以在运行时实时计算形状\n",
    "    print(\"build\")\n",
    "    self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]),\n",
    "                                         self.num_outputs])\n",
    "\n",
    "  def call(self, input):\n",
    "    print(input)\n",
    "    return tf.matmul(input, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\n",
      "tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it.\n",
    "# 执行的是__call__方法，我猜这个方法里会执行build与call"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>]\n",
      "['my_layer_3/embedding_9/embeddings:0', 'my_layer_3/embedding_10/embeddings:0', 'my_layer_3/embedding_11/embeddings:0']\n"
     ]
    }
   ],
   "source": [
    "class MyLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MyLayer, self).__init__()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.embed_layer1=tf.keras.layers.Embedding(input_dim=11,output_dim=4)\n",
    "    self.embed_layer2=tf.keras.layers.Embedding(input_dim=11,output_dim=4)\n",
    "    self.embed_layer3=tf.keras.layers.Embedding(input_dim=11,output_dim=4)\n",
    "\n",
    "  def call(self,input):\n",
    "    print(input) # 这个input是eagerTensor\n",
    "    cate_id,shop_id,brand_id=input[0],input[1],input[2]\n",
    "    cate_emb=self.embed_layer1(cate_id)\n",
    "    shop_emb=self.embed_layer2(shop_id)\n",
    "    brand_emb=self.embed_layer3(brand_id)\n",
    "    return tf.concat((cate_emb,shop_emb,brand_emb),axis=0)\n",
    "\n",
    "layer = MyLayer()\n",
    "layer([0,1,2])\n",
    "print([var.name for var in layer.trainable_variables])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_dense_layer/kernel:0']\n"
     ]
    }
   ],
   "source": [
    "print([var.name for var in layer.trainable_variables])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'my_dense_layer/kernel:0' shape=(5, 10) dtype=float32, numpy=\n array([[-0.50721896, -0.47232395, -0.1973064 ,  0.6243182 , -0.52000153,\n         -0.33274007, -0.54664564, -0.24344924,  0.20886755,  0.52766436],\n        [-0.10194582, -0.26520237,  0.40553063, -0.1508505 , -0.2437858 ,\n          0.00684595, -0.43593943,  0.5112054 , -0.01449776,  0.62161833],\n        [ 0.2649358 , -0.39786154, -0.38311344, -0.61532545,  0.41653258,\n          0.37220067, -0.5659071 ,  0.40570682,  0.02277929,  0.1916483 ],\n        [ 0.6030242 ,  0.40876168,  0.43201512,  0.5830526 ,  0.3149292 ,\n         -0.4627903 ,  0.20632708,  0.36614305,  0.4345067 , -0.6315632 ],\n        [ 0.07500148, -0.23751885, -0.13329414,  0.43967134,  0.40748554,\n         -0.06890881,  0.47799903,  0.6097793 , -0.455846  , -0.25933594]],\n       dtype=float32)>]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\narray([[[[0.94029474, 0.9919794 , 1.0313917 ],\n         [0.94029474, 0.9919794 , 1.0313917 ],\n         [0.94029474, 0.9919794 , 1.0313917 ]],\n\n        [[0.94029474, 0.9919794 , 1.0313917 ],\n         [0.94029474, 0.9919794 , 1.0313917 ],\n         [0.94029474, 0.9919794 , 1.0313917 ]]]], dtype=float32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(tf.ones([1, 2, 3, 3])) \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}